{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LptjI48IzfYx",
        "outputId": "bd479944-a1ce-4c31-dc26-159cf889a010"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m800.5/800.5 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.6/59.6 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.2/13.2 MB\u001b[0m \u001b[31m58.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.7/30.7 MB\u001b[0m \u001b[31m39.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m44.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.3/42.3 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.6/38.6 MB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m35.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m64.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m898.7/898.7 kB\u001b[0m \u001b[31m30.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m88.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m70.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m43.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m71.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.2/35.2 MB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m818.9/818.9 kB\u001b[0m \u001b[31m41.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.5/58.5 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.1/48.1 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.4/51.4 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.9/125.9 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m864.1/864.1 kB\u001b[0m \u001b[31m41.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.5/48.5 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m961.5/961.5 kB\u001b[0m \u001b[31m47.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m383.6/383.6 kB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.0/823.0 kB\u001b[0m \u001b[31m41.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m231.9/231.9 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.7/117.7 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m739.1/739.1 kB\u001b[0m \u001b[31m40.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for whisperx (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for julius (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install --q git+https://github.com/m-bain/whisperx.git openai-whisper pydub langchain openai faiss-cpu tiktoken sentence-transformers deep_translator moviepy nltk\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4nZMgluS7vOn",
        "outputId": "64fdd242-23ea-4b35-b51d-acfd10787156"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pandas==2.2.2\n",
            "  Downloading pandas-2.2.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas==2.2.2) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas==2.2.2) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas==2.2.2) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas==2.2.2) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas==2.2.2) (1.17.0)\n",
            "Downloading pandas-2.2.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m81.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pandas\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.2.3\n",
            "    Uninstalling pandas-2.2.3:\n",
            "      Successfully uninstalled pandas-2.2.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "whisperx 3.3.1 requires pandas>=2.2.3, but you have pandas 2.2.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed pandas-2.2.2\n"
          ]
        }
      ],
      "source": [
        "!pip install pandas==2.2.2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "94Byv46h9b3b",
        "outputId": "c2ed4b5e-8e85-4af8-8ac6-0fcbb68ebb7d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: deep_translator in /usr/local/lib/python3.11/dist-packages (1.11.4)\n",
            "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.9.1 in /usr/local/lib/python3.11/dist-packages (from deep_translator) (4.13.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from deep_translator) (2.32.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4<5.0.0,>=4.9.1->deep_translator) (2.6)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4<5.0.0,>=4.9.1->deep_translator) (4.13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.23.0->deep_translator) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.23.0->deep_translator) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.23.0->deep_translator) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.23.0->deep_translator) (2025.1.31)\n"
          ]
        }
      ],
      "source": [
        "!pip install deep_translator\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l9KiFFe79oO-",
        "outputId": "dfea1032-88f5-4b37-c9ab-31996017185b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.3.21-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting langchain-core<1.0.0,>=0.3.51 (from langchain-community)\n",
            "  Downloading langchain_core-0.3.51-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting langchain<1.0.0,>=0.3.23 (from langchain-community)\n",
            "  Downloading langchain-0.3.23-py3-none-any.whl.metadata (7.8 kB)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.40)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.11.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (9.1.2)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
            "  Downloading pydantic_settings-2.8.1-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.23)\n",
            "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: numpy<3,>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.2.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.18.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting langchain-text-splitters<1.0.0,>=0.3.8 (from langchain<1.0.0,>=0.3.23->langchain-community)\n",
            "  Downloading langchain_text_splitters-0.3.8-py3-none-any.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.23->langchain-community) (2.11.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.51->langchain-community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.51->langchain-community) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.51->langchain-community) (4.13.1)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (3.10.16)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.23.0)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community)\n",
            "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2025.1.31)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.51->langchain-community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.23->langchain-community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.23->langchain-community) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.23->langchain-community) (0.4.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.3.1)\n",
            "Downloading langchain_community-0.3.21-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading langchain-0.3.23-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.3.51-py3-none-any.whl (423 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m423.3/423.3 kB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_settings-2.8.1-py3-none-any.whl (30 kB)\n",
            "Downloading langchain_text_splitters-0.3.8-py3-none-any.whl (32 kB)\n",
            "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: python-dotenv, mypy-extensions, marshmallow, httpx-sse, typing-inspect, pydantic-settings, dataclasses-json, langchain-core, langchain-text-splitters, langchain, langchain-community\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.50\n",
            "    Uninstalling langchain-core-0.3.50:\n",
            "      Successfully uninstalled langchain-core-0.3.50\n",
            "  Attempting uninstall: langchain-text-splitters\n",
            "    Found existing installation: langchain-text-splitters 0.3.7\n",
            "    Uninstalling langchain-text-splitters-0.3.7:\n",
            "      Successfully uninstalled langchain-text-splitters-0.3.7\n",
            "  Attempting uninstall: langchain\n",
            "    Found existing installation: langchain 0.3.22\n",
            "    Uninstalling langchain-0.3.22:\n",
            "      Successfully uninstalled langchain-0.3.22\n",
            "Successfully installed dataclasses-json-0.6.7 httpx-sse-0.4.0 langchain-0.3.23 langchain-community-0.3.21 langchain-core-0.3.51 langchain-text-splitters-0.3.8 marshmallow-3.26.1 mypy-extensions-1.0.0 pydantic-settings-2.8.1 python-dotenv-1.1.0 typing-inspect-0.9.0\n"
          ]
        }
      ],
      "source": [
        "!pip install -U langchain-community\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hpXVueqN86wf",
        "outputId": "4fe5863b-64ae-4e87-bf50-2133d82731a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/m-bain/whisperx.git\n",
            "  Cloning https://github.com/m-bain/whisperx.git to /tmp/pip-req-build-e1o5t5fk\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/m-bain/whisperx.git /tmp/pip-req-build-e1o5t5fk\n",
            "  Resolved https://github.com/m-bain/whisperx.git to commit f10dbf6ab1717e84db7733df9c0b21658ee68f9b\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: ctranslate2>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from whisperx==3.3.1) (4.5.0)\n",
            "Requirement already satisfied: faster-whisper>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from whisperx==3.3.1) (1.1.1)\n",
            "Requirement already satisfied: nltk>=3.9.1 in /usr/local/lib/python3.11/dist-packages (from whisperx==3.3.1) (3.9.1)\n",
            "Requirement already satisfied: numpy>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from whisperx==3.3.1) (2.0.2)\n",
            "Requirement already satisfied: onnxruntime==1.19 in /usr/local/lib/python3.11/dist-packages (from whisperx==3.3.1) (1.19.0)\n",
            "Collecting pandas>=2.2.3 (from whisperx==3.3.1)\n",
            "  Using cached pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
            "Requirement already satisfied: pyannote-audio>=3.3.2 in /usr/local/lib/python3.11/dist-packages (from whisperx==3.3.1) (3.3.2)\n",
            "Requirement already satisfied: torch>=2.5.1 in /usr/local/lib/python3.11/dist-packages (from whisperx==3.3.1) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchaudio>=2.5.1 in /usr/local/lib/python3.11/dist-packages (from whisperx==3.3.1) (2.6.0+cu124)\n",
            "Requirement already satisfied: transformers>=4.48.0 in /usr/local/lib/python3.11/dist-packages (from whisperx==3.3.1) (4.50.3)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.11/dist-packages (from onnxruntime==1.19->whisperx==3.3.1) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime==1.19->whisperx==3.3.1) (25.2.10)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from onnxruntime==1.19->whisperx==3.3.1) (24.2)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime==1.19->whisperx==3.3.1) (5.29.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime==1.19->whisperx==3.3.1) (1.13.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from ctranslate2>=4.5.0->whisperx==3.3.1) (75.2.0)\n",
            "Requirement already satisfied: pyyaml<7,>=5.3 in /usr/local/lib/python3.11/dist-packages (from ctranslate2>=4.5.0->whisperx==3.3.1) (6.0.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.13 in /usr/local/lib/python3.11/dist-packages (from faster-whisper>=1.1.1->whisperx==3.3.1) (0.30.1)\n",
            "Requirement already satisfied: tokenizers<1,>=0.13 in /usr/local/lib/python3.11/dist-packages (from faster-whisper>=1.1.1->whisperx==3.3.1) (0.21.1)\n",
            "Requirement already satisfied: av>=11 in /usr/local/lib/python3.11/dist-packages (from faster-whisper>=1.1.1->whisperx==3.3.1) (14.3.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from faster-whisper>=1.1.1->whisperx==3.3.1) (4.67.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk>=3.9.1->whisperx==3.3.1) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk>=3.9.1->whisperx==3.3.1) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk>=3.9.1->whisperx==3.3.1) (2024.11.6)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.2.3->whisperx==3.3.1) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.2.3->whisperx==3.3.1) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.2.3->whisperx==3.3.1) (2025.2)\n",
            "Requirement already satisfied: asteroid-filterbanks>=0.4 in /usr/local/lib/python3.11/dist-packages (from pyannote-audio>=3.3.2->whisperx==3.3.1) (0.4.0)\n",
            "Requirement already satisfied: einops>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pyannote-audio>=3.3.2->whisperx==3.3.1) (0.8.1)\n",
            "Requirement already satisfied: lightning>=2.0.1 in /usr/local/lib/python3.11/dist-packages (from pyannote-audio>=3.3.2->whisperx==3.3.1) (2.5.1)\n",
            "Requirement already satisfied: omegaconf<3.0,>=2.1 in /usr/local/lib/python3.11/dist-packages (from pyannote-audio>=3.3.2->whisperx==3.3.1) (2.3.0)\n",
            "Requirement already satisfied: pyannote.core>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from pyannote-audio>=3.3.2->whisperx==3.3.1) (5.0.0)\n",
            "Requirement already satisfied: pyannote.database>=5.0.1 in /usr/local/lib/python3.11/dist-packages (from pyannote-audio>=3.3.2->whisperx==3.3.1) (5.1.3)\n",
            "Requirement already satisfied: pyannote.metrics>=3.2 in /usr/local/lib/python3.11/dist-packages (from pyannote-audio>=3.3.2->whisperx==3.3.1) (3.2.1)\n",
            "Requirement already satisfied: pyannote.pipeline>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from pyannote-audio>=3.3.2->whisperx==3.3.1) (3.0.1)\n",
            "Requirement already satisfied: pytorch-metric-learning>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from pyannote-audio>=3.3.2->whisperx==3.3.1) (2.8.1)\n",
            "Requirement already satisfied: rich>=12.0.0 in /usr/local/lib/python3.11/dist-packages (from pyannote-audio>=3.3.2->whisperx==3.3.1) (13.9.4)\n",
            "Requirement already satisfied: semver>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from pyannote-audio>=3.3.2->whisperx==3.3.1) (3.0.4)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.11/dist-packages (from pyannote-audio>=3.3.2->whisperx==3.3.1) (0.13.1)\n",
            "Requirement already satisfied: speechbrain>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from pyannote-audio>=3.3.2->whisperx==3.3.1) (1.0.3)\n",
            "Requirement already satisfied: tensorboardX>=2.6 in /usr/local/lib/python3.11/dist-packages (from pyannote-audio>=3.3.2->whisperx==3.3.1) (2.6.2.2)\n",
            "Requirement already satisfied: torch-audiomentations>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from pyannote-audio>=3.3.2->whisperx==3.3.1) (0.12.0)\n",
            "Requirement already satisfied: torchmetrics>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from pyannote-audio>=3.3.2->whisperx==3.3.1) (1.7.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->whisperx==3.3.1) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->whisperx==3.3.1) (4.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->whisperx==3.3.1) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->whisperx==3.3.1) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->whisperx==3.3.1) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->whisperx==3.3.1) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->whisperx==3.3.1) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->whisperx==3.3.1) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->whisperx==3.3.1) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->whisperx==3.3.1) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->whisperx==3.3.1) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->whisperx==3.3.1) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->whisperx==3.3.1) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->whisperx==3.3.1) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->whisperx==3.3.1) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->whisperx==3.3.1) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->whisperx==3.3.1) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->whisperx==3.3.1) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->whisperx==3.3.1) (3.2.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime==1.19->whisperx==3.3.1) (1.3.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers>=4.48.0->whisperx==3.3.1) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.48.0->whisperx==3.3.1) (0.5.3)\n",
            "Requirement already satisfied: lightning-utilities<2.0,>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from lightning>=2.0.1->pyannote-audio>=3.3.2->whisperx==3.3.1) (0.14.3)\n",
            "Requirement already satisfied: pytorch-lightning in /usr/local/lib/python3.11/dist-packages (from lightning>=2.0.1->pyannote-audio>=3.3.2->whisperx==3.3.1) (2.5.1)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.11/dist-packages (from omegaconf<3.0,>=2.1->pyannote-audio>=3.3.2->whisperx==3.3.1) (4.9.3)\n",
            "Requirement already satisfied: sortedcontainers>=2.0.4 in /usr/local/lib/python3.11/dist-packages (from pyannote.core>=5.0.0->pyannote-audio>=3.3.2->whisperx==3.3.1) (2.4.0)\n",
            "Requirement already satisfied: scipy>=1.1 in /usr/local/lib/python3.11/dist-packages (from pyannote.core>=5.0.0->pyannote-audio>=3.3.2->whisperx==3.3.1) (1.14.1)\n",
            "Requirement already satisfied: typer>=0.12.1 in /usr/local/lib/python3.11/dist-packages (from pyannote.database>=5.0.1->pyannote-audio>=3.3.2->whisperx==3.3.1) (0.15.2)\n",
            "Requirement already satisfied: scikit-learn>=0.17.1 in /usr/local/lib/python3.11/dist-packages (from pyannote.metrics>=3.2->pyannote-audio>=3.3.2->whisperx==3.3.1) (1.6.1)\n",
            "Requirement already satisfied: docopt>=0.6.2 in /usr/local/lib/python3.11/dist-packages (from pyannote.metrics>=3.2->pyannote-audio>=3.3.2->whisperx==3.3.1) (0.6.2)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.11/dist-packages (from pyannote.metrics>=3.2->pyannote-audio>=3.3.2->whisperx==3.3.1) (0.9.0)\n",
            "Requirement already satisfied: matplotlib>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from pyannote.metrics>=3.2->pyannote-audio>=3.3.2->whisperx==3.3.1) (3.10.0)\n",
            "Requirement already satisfied: optuna>=3.1 in /usr/local/lib/python3.11/dist-packages (from pyannote.pipeline>=3.0.1->pyannote-audio>=3.3.2->whisperx==3.3.1) (4.2.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=2.2.3->whisperx==3.3.1) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=12.0.0->pyannote-audio>=3.3.2->whisperx==3.3.1) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=12.0.0->pyannote-audio>=3.3.2->whisperx==3.3.1) (2.18.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile>=0.12.1->pyannote-audio>=3.3.2->whisperx==3.3.1) (1.17.1)\n",
            "Requirement already satisfied: hyperpyyaml in /usr/local/lib/python3.11/dist-packages (from speechbrain>=1.0.0->pyannote-audio>=3.3.2->whisperx==3.3.1) (1.2.2)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from speechbrain>=1.0.0->pyannote-audio>=3.3.2->whisperx==3.3.1) (0.2.0)\n",
            "Requirement already satisfied: julius<0.3,>=0.2.3 in /usr/local/lib/python3.11/dist-packages (from torch-audiomentations>=0.11.0->pyannote-audio>=3.3.2->whisperx==3.3.1) (0.2.7)\n",
            "Requirement already satisfied: torch-pitch-shift>=1.2.2 in /usr/local/lib/python3.11/dist-packages (from torch-audiomentations>=0.11.0->pyannote-audio>=3.3.2->whisperx==3.3.1) (1.2.5)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.11/dist-packages (from coloredlogs->onnxruntime==1.19->whisperx==3.3.1) (10.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.5.1->whisperx==3.3.1) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers>=4.48.0->whisperx==3.3.1) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers>=4.48.0->whisperx==3.3.1) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers>=4.48.0->whisperx==3.3.1) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers>=4.48.0->whisperx==3.3.1) (2025.1.31)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile>=0.12.1->pyannote-audio>=3.3.2->whisperx==3.3.1) (2.22)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<2026.0,>=2022.5.0->lightning>=2.0.1->pyannote-audio>=3.3.2->whisperx==3.3.1) (3.11.15)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=12.0.0->pyannote-audio>=3.3.2->whisperx==3.3.1) (0.1.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote-audio>=3.3.2->whisperx==3.3.1) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote-audio>=3.3.2->whisperx==3.3.1) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote-audio>=3.3.2->whisperx==3.3.1) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote-audio>=3.3.2->whisperx==3.3.1) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote-audio>=3.3.2->whisperx==3.3.1) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote-audio>=3.3.2->whisperx==3.3.1) (3.2.3)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote-audio>=3.3.2->whisperx==3.3.1) (1.15.2)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.11/dist-packages (from optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote-audio>=3.3.2->whisperx==3.3.1) (6.9.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote-audio>=3.3.2->whisperx==3.3.1) (2.0.40)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.17.1->pyannote.metrics>=3.2->pyannote-audio>=3.3.2->whisperx==3.3.1) (3.6.0)\n",
            "Requirement already satisfied: primePy>=1.3 in /usr/local/lib/python3.11/dist-packages (from torch-pitch-shift>=1.2.2->torch-audiomentations>=0.11.0->pyannote-audio>=3.3.2->whisperx==3.3.1) (1.3)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.12.1->pyannote.database>=5.0.1->pyannote-audio>=3.3.2->whisperx==3.3.1) (1.5.4)\n",
            "Requirement already satisfied: ruamel.yaml>=0.17.28 in /usr/local/lib/python3.11/dist-packages (from hyperpyyaml->speechbrain>=1.0.0->pyannote-audio>=3.3.2->whisperx==3.3.1) (0.18.10)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning>=2.0.1->pyannote-audio>=3.3.2->whisperx==3.3.1) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning>=2.0.1->pyannote-audio>=3.3.2->whisperx==3.3.1) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning>=2.0.1->pyannote-audio>=3.3.2->whisperx==3.3.1) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning>=2.0.1->pyannote-audio>=3.3.2->whisperx==3.3.1) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning>=2.0.1->pyannote-audio>=3.3.2->whisperx==3.3.1) (6.2.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning>=2.0.1->pyannote-audio>=3.3.2->whisperx==3.3.1) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning>=2.0.1->pyannote-audio>=3.3.2->whisperx==3.3.1) (1.18.3)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote-audio>=3.3.2->whisperx==3.3.1) (1.1.3)\n",
            "Requirement already satisfied: ruamel.yaml.clib>=0.2.7 in /usr/local/lib/python3.11/dist-packages (from ruamel.yaml>=0.17.28->hyperpyyaml->speechbrain>=1.0.0->pyannote-audio>=3.3.2->whisperx==3.3.1) (0.2.12)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote-audio>=3.3.2->whisperx==3.3.1) (3.1.1)\n",
            "Using cached pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
            "Installing collected packages: pandas\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.2.2\n",
            "    Uninstalling pandas-2.2.2:\n",
            "      Successfully uninstalled pandas-2.2.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed pandas-2.2.3\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/m-bain/whisperx.git\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WJg_nn3-8Hwj",
        "outputId": "fd4dee21-7957-4321-bf97-346f3da7e368"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai-whisper in /usr/local/lib/python3.11/dist-packages (20240930)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (0.60.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (2.0.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (2.6.0+cu124)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (4.67.1)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (10.6.0)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (0.9.0)\n",
            "Requirement already satisfied: triton>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (3.2.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba->openai-whisper) (0.43.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken->openai-whisper) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken->openai-whisper) (2.32.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (4.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (12.4.127)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->openai-whisper) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2025.1.31)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->openai-whisper) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install openai-whisper\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing Libraries\n",
        "import whisper\n",
        "import whisperx\n",
        "import csv\n",
        "import gc\n",
        "from deep_translator import GoogleTranslator  # Updated translator module\n",
        "import os\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from typing_extensions import Concatenate\n",
        "import heapq\n",
        "import urllib.request\n",
        "import re\n",
        "from moviepy.editor import AudioFileClip\n",
        "import pandas as pd\n",
        "import google.generativeai as genai  # Using Google Gemini instead of OpenAI\n",
        "import smtplib\n",
        "from email.mime.text import MIMEText\n",
        "from email.mime.multipart import MIMEMultipart\n",
        "import random\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8RWp9qLzguwT",
        "outputId": "ed419233-fc2f-484a-e66e-b93a56b69e00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:speechbrain.utils.checkpoints:Registered checkpoint save hook for _speechbrain_save\n",
            "DEBUG:speechbrain.utils.checkpoints:Registered checkpoint load hook for _speechbrain_load\n",
            "DEBUG:speechbrain.utils.checkpoints:Registered checkpoint save hook for save\n",
            "DEBUG:speechbrain.utils.checkpoints:Registered checkpoint load hook for load\n",
            "DEBUG:speechbrain.utils.checkpoints:Registered checkpoint save hook for _save\n",
            "DEBUG:speechbrain.utils.checkpoints:Registered checkpoint load hook for _recover\n",
            "WARNING:py.warnings:/usr/local/lib/python3.11/dist-packages/moviepy/video/io/sliders.py:61: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
            "  if event.key is 'enter':\n",
            "\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xdl-WubdARvk"
      },
      "outputs": [],
      "source": [
        "genai.configure(api_key=\"AIzaSyBX9yIYHClYBl2PiEnshnh6OHm0dssXWwM\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vQE1H4laA0cO"
      },
      "outputs": [],
      "source": [
        "def mp4tomp3(video_file_path, mp3_file_path):\n",
        "    try:\n",
        "        audio = AudioFileClip(video_file_path)\n",
        "        audio.write_audiofile(mp3_file_path, codec='mp3')\n",
        "        print(f\"Converted {video_file_path} to {mp3_file_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error converting video: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3SAEsrvFA2qp"
      },
      "outputs": [],
      "source": [
        "def transcribe_audio(file_path):\n",
        "    print(\"🔄 Transcribing audio using Whisper...\")\n",
        "    model = whisper.load_model(\"small\")\n",
        "    result = model.transcribe(file_path)\n",
        "    print(\"✅ Transcription completed!\")\n",
        "    return result[\"text\"]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a6dkjf99LTVh"
      },
      "outputs": [],
      "source": [
        "def save_transcript(transcript, transcript_file):\n",
        "    try:\n",
        "        with open(transcript_file, \"w\", encoding=\"utf-8\") as f:\n",
        "            f.write(transcript)\n",
        "        print(f\"✅ Transcript saved at: {transcript_file}\")\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error saving transcript: {e}\")\n",
        "        print(f\"Error saving transcript: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tMHwJrOQLX1i"
      },
      "outputs": [],
      "source": [
        "# Function to read transcript from file\n",
        "def get_transcript_from_file(transcript_file):\n",
        "    try:\n",
        "        with open(transcript_file, \"r\", encoding=\"utf-8\") as f:\n",
        "            transcript = f.read()\n",
        "        print(f\"✅ Transcript loaded from: {transcript_file}\")\n",
        "        return transcript\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error reading transcript file: {e}\")\n",
        "        return \"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# List of available languages\n",
        "LANGUAGES = {\n",
        "    \"1\": \"hi\",  # Hindi\n",
        "    \"2\": \"bn\",  # Bengali\n",
        "    \"3\": \"te\",  # Telugu\n",
        "    \"4\": \"mr\",  # Marathi\n",
        "    \"5\": \"ta\",  # Tamil\n",
        "    \"6\": \"ur\",  # Urdu\n",
        "    \"7\": \"gu\",  # Gujarati\n",
        "    \"8\": \"kn\",  # Kannada\n",
        "    \"9\": \"ml\",  # Malayalam\n",
        "    \"10\": \"en\"  # English\n",
        "}"
      ],
      "metadata": {
        "id": "aIXcfWpFeZDF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PhSJv5JUA4xk"
      },
      "outputs": [],
      "source": [
        "def translate_text(text, target_lang=\"bn\"):\n",
        "    try:\n",
        "        return GoogleTranslator(source=\"auto\", target=target_lang).translate(text)\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Translation failed: {e}\")\n",
        "        return text"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import google.generativeai as genai\n",
        "\n",
        "# Set up Gemini API key (Replace with your actual API key)\n",
        "genai.configure(api_key=\"AIzaSyBX9yIYHClYBl2PiEnshnh6OHm0dssXWwM\")\n",
        "\n",
        "# Function to read transcript file\n",
        "def get_transcript_from_file():\n",
        "    transcript_file = input(\"📂 Enter the path of the transcript file (e.g., transcript.txt): \").strip()\n",
        "\n",
        "    if not os.path.exists(transcript_file):\n",
        "        print(\"❌ Error: Transcript file not found! Please provide a valid file.\")\n",
        "        return None\n",
        "\n",
        "    try:\n",
        "        with open(transcript_file, \"r\", encoding=\"utf-8\") as f:\n",
        "            transcript = f.read()\n",
        "        print(\"✅ Transcript loaded successfully!\")\n",
        "        return transcript\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error reading transcript file: {e}\")\n",
        "        return None\n",
        "\n",
        "# Function to create chatbot (restricts answers to meeting context)\n",
        "def chatbot_meeting(transcript):\n",
        "    print(\"\\n💬 **Meeting Chatbot is ready! Ask questions related to the meeting.**\")\n",
        "    print(\"🔹 Type 'exit' to quit.\\n\")\n",
        "\n",
        "    model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
        "\n",
        "    while True:\n",
        "        question = input(\"❓ Your Question: \").strip()\n",
        "        if question.lower() == \"exit\":\n",
        "            print(\"👋 Exiting chatbot. Have a great day!\")\n",
        "            break\n",
        "\n",
        "        prompt = f\"\"\"\n",
        "        You are a chatbot that answers only questions related to the following meeting transcript.\n",
        "        Do **NOT** answer anything outside this meeting's context. If the question is unrelated, simply reply:\n",
        "        'I'm only here to discuss this meeting.'\n",
        "\n",
        "        **Meeting Transcript:**\n",
        "        {transcript}\n",
        "\n",
        "        **User Question:** {question}\n",
        "\n",
        "        **Answer:**\n",
        "        \"\"\"\n",
        "\n",
        "        response = model.generate_content(prompt)\n",
        "        print(f\"💡 Chatbot: {response.text}\\n\")\n",
        "\n",
        "# Run the chatbot with transcript input\n",
        "transcript = get_transcript_from_file()\n",
        "if transcript:\n",
        "    chatbot_meeting(transcript)\n"
      ],
      "metadata": {
        "id": "okL78_L2eXqk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 662
        },
        "outputId": "a2a7c2e6-6e51-425d-8de4-7dc65c5d8c69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📂 Enter the path of the transcript file (e.g., transcript.txt): /content/drive/MyDrive/tarp1/meet_transcript.txt\n",
            "✅ Transcript loaded successfully!\n",
            "\n",
            "💬 **Meeting Chatbot is ready! Ask questions related to the meeting.**\n",
            "🔹 Type 'exit' to quit.\n",
            "\n",
            "❓ Your Question: what is the key point of the meeting?\n",
            "💡 Chatbot: The key point of the meeting was to finalize the website scope for ACME Corporation's new business website, assign key tasks, and set deadlines for its development.\n",
            "\n",
            "\n",
            "❓ Your Question: prepare a checklist for the April 10 internal review based on the tasks discussed?\n",
            "💡 Chatbot: **ACME Corporation Website Development - Internal Review Checklist (April 10, 2025)**\n",
            "\n",
            "**Content & Marketing (Himanshu):**\n",
            "\n",
            "* [ ] All website content provided (company details, service descriptions, blog drafts).\n",
            "\n",
            "**Development (Vibhuti):**\n",
            "\n",
            "* [ ] Homepage layout complete (first draft).\n",
            "* [ ] Lead capture form complete (first draft), integrated with HubSpot CRM via API.\n",
            "\n",
            "**Project Management:**\n",
            "\n",
            "* [ ] Complete project roadmap defined (including milestones and testing strategy).\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "❓ Your Question: WHo is SRK?\n",
            "💡 Chatbot: I'm only here to discuss this meeting.\n",
            "\n",
            "\n",
            "❓ Your Question: exit\n",
            "👋 Exiting chatbot. Have a great day!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ec9v8M5gHdPh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RZyFpEcxA8Sf"
      },
      "outputs": [],
      "source": [
        "def generate_mom_gemini(transcript):\n",
        "    print(\"🔄 Generating Meeting Summary (MOM) using Gemini AI...\")\n",
        "    prompt = f\"\"\"\n",
        "    Given the following meeting transcript, generate a structured meeting summary including:\n",
        "    - **Title**\n",
        "    - **Agenda (max 3 points)**\n",
        "    - **Key discussion points**\n",
        "    - **Tasks assigned to attendees**\n",
        "    - **Action items**\n",
        "\n",
        "    **Transcript:**\n",
        "    {transcript}\n",
        "\n",
        "    Return the response in a structured format.\n",
        "    \"\"\"\n",
        "    model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
        "    response = model.generate_content(prompt)\n",
        "    print(\"✅ MOM generated successfully!\")\n",
        "    return response.text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zPY4VGrxA_UC"
      },
      "outputs": [],
      "source": [
        "# Function to save MOM as text file\n",
        "def save_mom(mom_text, output_file):\n",
        "    try:\n",
        "        with open(output_file, \"w\", encoding=\"utf-8\") as file:\n",
        "            file.write(mom_text)\n",
        "        print(f\"✅ MOM saved at: {output_file}\")\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error saving MOM: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yqDKu_JeBBTn"
      },
      "outputs": [],
      "source": [
        "def process_meeting():\n",
        "    # Step 1: Get video input from the user\n",
        "    video_path = input(\"📂 Enter the path of the video file (e.g., meeting.mp4): \").strip()\n",
        "\n",
        "    # Ensure file exists\n",
        "    if not os.path.exists(video_path):\n",
        "        print(\"❌ Error: Video file not found! Please provide a valid path.\")\n",
        "        return\n",
        "\n",
        "    # Generate file paths dynamically\n",
        "    base_name = os.path.splitext(video_path)[0]\n",
        "    audio_path = f\"{base_name}.mp3\"\n",
        "    transcript_file = f\"{base_name}_transcript.txt\"\n",
        "    mom_file = f\"{base_name}_meeting_minutes.txt\"\n",
        "\n",
        "    # Step 2: Convert MP4 to MP3\n",
        "    mp4tomp3(video_path, audio_path)\n",
        "\n",
        "    # Step 3: Transcribe the audio\n",
        "    transcript = transcribe_audio(audio_path)\n",
        "    save_transcript(transcript, transcript_file)\n",
        "\n",
        "    # Step 4: (Optional) Translate transcript if needed\n",
        "    # Example: To translate to Hindi, use translate_text(transcript, \"hi\")\n",
        "\n",
        "    # Step 5: Generate MOM using Gemini\n",
        "    mom_text = generate_mom_gemini(transcript)\n",
        "    save_mom(mom_text, mom_file)\n",
        "\n",
        "    print(\"\\n🎉 ✅ Process Completed! Your transcript and MOM are ready.\")\n",
        "    print(f\"📜 Transcript: {transcript_file}\")\n",
        "    print(f\"📑 Meeting Summary (MOM): {mom_file}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358
        },
        "id": "U30ErcDPBFoq",
        "outputId": "b326526a-afff-41da-8514-b725cfadbbac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📂 Enter the path of the video file (e.g., meeting.mp4): /content/drive/MyDrive/tarp/meet.mp4\n",
            "MoviePy - Writing audio in /content/drive/MyDrive/tarp/meet.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n",
            "Converted /content/drive/MyDrive/tarp/meet.mp4 to /content/drive/MyDrive/tarp/meet.mp3\n",
            "🔄 Transcribing audio using Whisper...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████████████████████████████████| 461M/461M [00:05<00:00, 85.8MiB/s]\n",
            "WARNING:py.warnings:/usr/local/lib/python3.11/dist-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Transcription completed!\n",
            "✅ Transcript saved at: /content/drive/MyDrive/tarp/meet_transcript.txt\n",
            "🔄 Generating Meeting Summary (MOM) using Gemini AI...\n",
            "✅ MOM generated successfully!\n",
            "✅ MOM saved at: /content/drive/MyDrive/tarp/meet_meeting_minutes.txt\n",
            "\n",
            "🎉 ✅ Process Completed! Your transcript and MOM are ready.\n",
            "📜 Transcript: /content/drive/MyDrive/tarp/meet_transcript.txt\n",
            "📑 Meeting Summary (MOM): /content/drive/MyDrive/tarp/meet_meeting_minutes.txt\n"
          ]
        }
      ],
      "source": [
        "process_meeting()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uye1EiylKjZT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af76fdc6-c728-4d55-d602-9fbc56a2a8c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📂 Enter the path of the transcript file (e.g., transcript.txt): /content/drive/MyDrive/tarp/meet_meeting_minutes.txt\n",
            "\n",
            "🌍 Available Languages:\n",
            "1. Hi\n",
            "2. Bn\n",
            "3. Te\n",
            "4. Mr\n",
            "5. Ta\n",
            "6. Ur\n",
            "7. Gu\n",
            "8. Kn\n",
            "9. Ml\n",
            "10. En\n",
            "\n",
            "🔹 Enter the number for your preferred language: 5\n",
            "🔄 Translating transcript into Ta...\n",
            "✅ Translation saved at: /content/drive/MyDrive/tarp/meet_meeting_minutes_ta.txt\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from deep_translator import GoogleTranslator\n",
        "\n",
        "# List of available languages\n",
        "LANGUAGES = {\n",
        "    \"1\": \"hi\",  # Hindi\n",
        "    \"2\": \"bn\",  # Bengali\n",
        "    \"3\": \"te\",  # Telugu\n",
        "    \"4\": \"mr\",  # Marathi\n",
        "    \"5\": \"ta\",  # Tamil\n",
        "    \"6\": \"ur\",  # Urdu\n",
        "    \"7\": \"gu\",  # Gujarati\n",
        "    \"8\": \"kn\",  # Kannada\n",
        "    \"9\": \"ml\",  # Malayalam\n",
        "    \"10\": \"en\"  # English\n",
        "}\n",
        "\n",
        "# Function to translate text\n",
        "def translate_text(text, target_lang):\n",
        "    try:\n",
        "        return GoogleTranslator(source=\"auto\", target=target_lang).translate(text)\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Translation failed for {target_lang}: {e}\")\n",
        "        return text\n",
        "\n",
        "# Function to translate a transcript file\n",
        "def translate_transcript_file():\n",
        "    # Step 1: Ask for transcript file\n",
        "    transcript_file = input(\"📂 Enter the path of the transcript file (e.g., transcript.txt): \").strip()\n",
        "\n",
        "    if not os.path.exists(transcript_file):\n",
        "        print(\"❌ Error: File not found! Please provide a valid transcript file.\")\n",
        "        return\n",
        "\n",
        "    # Step 2: Read the transcript\n",
        "    try:\n",
        "        with open(transcript_file, \"r\", encoding=\"utf-8\") as f:\n",
        "            transcript = f.read()\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error reading transcript file: {e}\")\n",
        "        return\n",
        "\n",
        "    # Step 3: Choose language\n",
        "    print(\"\\n🌍 Available Languages:\")\n",
        "    for key, lang in LANGUAGES.items():\n",
        "        print(f\"{key}. {lang.capitalize()}\")\n",
        "\n",
        "    selected_lang = input(\"\\n🔹 Enter the number for your preferred language: \").strip()\n",
        "\n",
        "    if selected_lang not in LANGUAGES:\n",
        "        print(\"❌ Invalid selection. Please choose a valid language number.\")\n",
        "        return\n",
        "\n",
        "    target_lang = LANGUAGES[selected_lang]\n",
        "\n",
        "    # Step 4: Translate the transcript\n",
        "    print(f\"🔄 Translating transcript into {target_lang.capitalize()}...\")\n",
        "    translated_text = translate_text(transcript, target_lang)\n",
        "\n",
        "    # Step 5: Save translated file\n",
        "    translated_file = transcript_file.replace(\".txt\", f\"_{target_lang}.txt\")\n",
        "    try:\n",
        "        with open(translated_file, \"w\", encoding=\"utf-8\") as f:\n",
        "            f.write(translated_text)\n",
        "        print(f\"✅ Translation saved at: {translated_file}\")\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error saving translated file: {e}\")\n",
        "\n",
        "# Run the translation function\n",
        "translate_transcript_file()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Add Task and Deadline into the attendance sheet\n",
        "import csv\n",
        "import os\n",
        "import google.generativeai as genai\n",
        "\n",
        "# Set up Gemini API key (Replace with your actual API key)\n",
        "genai.configure(api_key=\"AIzaSyBX9yIYHClYBl2PiEnshnh6OHm0dssXWwM\")\n",
        "\n",
        "# Function to load attendees from CSV file\n",
        "def load_attendees_from_csv(csv_file):\n",
        "    with open(csv_file, 'r', encoding='utf-8') as file:\n",
        "        reader = csv.DictReader(file)\n",
        "        attendees = [row for row in reader]\n",
        "    return attendees\n",
        "\n",
        "# Load attendees from CSV\n",
        "csv_file_path = \"/content/drive/MyDrive/tarp1/attandence.csv\"  # Change to your actual file path\n",
        "attendees = load_attendees_from_csv(csv_file_path)\n",
        "\n",
        "# Load the transcript text file\n",
        "transcript_file_path = \"/content/drive/MyDrive/tarp1/meet_transcript.txt\"  # Change to your actual file path\n",
        "try:\n",
        "    with open(transcript_file_path, 'r', encoding='utf-8') as file:\n",
        "        transcript_text = file.read()\n",
        "except FileNotFoundError:\n",
        "    print(f\"❌ Error: Transcript file '{transcript_file_path}' not found!\")\n",
        "    exit()\n",
        "\n",
        "# Function to extract tasks and deadlines using Gemini\n",
        "def extract_tasks_and_deadlines(attendee_name, transcript_text):\n",
        "    prompt = f\"\"\"\n",
        "    From the given meeting transcript, extract and list only the tasks and deadlines assigned to {attendee_name}.\n",
        "    If there are no specific tasks assigned, respond with 'No tasks assigned.'\n",
        "\n",
        "    **Meeting Transcript:**\n",
        "    {transcript_text}\n",
        "\n",
        "    **Tasks & Deadlines for {attendee_name}:**\n",
        "    \"\"\"\n",
        "\n",
        "    model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
        "    response = model.generate_content(prompt)\n",
        "\n",
        "    return response.text.strip() if response.text else \"No tasks assigned.\"\n",
        "\n",
        "# Extract tasks and deadlines for all attendees\n",
        "for attendee in attendees:\n",
        "    name = attendee['\\ufeffFirst name']\n",
        "    tasks_and_deadlines = extract_tasks_and_deadlines(name, transcript_text)\n",
        "    attendee['Tasks & Deadlines'] = tasks_and_deadlines  # Add new column\n",
        "\n",
        "# Write updated data back to CSV\n",
        "output_csv_path = \"updated_attendance.csv\"  # Change to your desired output file\n",
        "with open(output_csv_path, 'w', newline='', encoding='utf-8') as csvfile:\n",
        "    writer = csv.DictWriter(csvfile, fieldnames=attendees[0].keys())\n",
        "    writer.writeheader()\n",
        "    writer.writerows(attendees)\n",
        "\n",
        "print(f\"✅ Tasks and deadlines added to '{output_csv_path}' for attendees with existing data.\")\n"
      ],
      "metadata": {
        "id": "p5YsuEUc2uzx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "191a5e3e-da00-41cd-bbbe-adc127370ad6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Tasks and deadlines added to 'updated_attendance.csv' for attendees with existing data.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import os\n",
        "import google.generativeai as genai\n",
        "\n",
        "# Set up Gemini API key (Replace with your actual API key)\n",
        "genai.configure(api_key=\"AIzaSyBX9yIYHClYBl2PiEnshnh6OHm0dssXWwM\")\n",
        "\n",
        "# Function to load attendees from CSV file\n",
        "def load_attendees_from_csv(csv_file):\n",
        "    with open(csv_file, 'r', encoding='utf-8') as file:\n",
        "        reader = csv.DictReader(file)\n",
        "        attendees = [row for row in reader]\n",
        "    return attendees\n",
        "\n",
        "# Load attendees from CSV\n",
        "csv_file_path = \"/content/drive/MyDrive/tarp1/attandence.csv\"  # Change to your actual file path\n",
        "attendees = load_attendees_from_csv(csv_file_path)\n",
        "\n",
        "# 🔹 Print column names to check what's inside\n",
        "if attendees:\n",
        "    print(\"🔹 Available columns in CSV:\", attendees[0].keys())\n",
        "\n",
        "# Find the correct name column\n",
        "possible_name_columns = [\"\\ufeffFirst name\", \"Last name\", \"Email\", \"Duration\"]\n",
        "name_column = None\n",
        "\n",
        "for col in possible_name_columns:\n",
        "    if col in attendees[0]:\n",
        "        name_column = col\n",
        "        break\n",
        "\n",
        "if not name_column:\n",
        "    print(\"❌ Error: No valid 'name' column found in the CSV!\")\n",
        "    exit()\n",
        "\n",
        "# Load the transcript text file\n",
        "transcript_file_path = \"/content/drive/MyDrive/tarp1/meet_transcript.txt\"  # Change to your actual file path\n",
        "try:\n",
        "    with open(transcript_file_path, 'r', encoding='utf-8') as file:\n",
        "        transcript_text = file.read()\n",
        "except FileNotFoundError:\n",
        "    print(f\"❌ Error: Transcript file '{transcript_file_path}' not found!\")\n",
        "    exit()\n",
        "\n",
        "# Function to extract tasks and deadlines using Gemini\n",
        "def extract_tasks_and_deadlines(attendee_name, transcript_text):\n",
        "    prompt = f\"\"\"\n",
        "    From the given meeting transcript, extract and list only the tasks and deadlines assigned to {attendee_name}.\n",
        "    If there are no specific tasks assigned, respond with 'No tasks assigned.'\n",
        "\n",
        "    **Meeting Transcript:**\n",
        "    {transcript_text}\n",
        "\n",
        "    **Tasks & Deadlines for {attendee_name}:**\n",
        "    \"\"\"\n",
        "\n",
        "    model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
        "    response = model.generate_content(prompt)\n",
        "\n",
        "    return response.text.strip() if response.text else \"No tasks assigned.\"\n",
        "\n",
        "# Extract tasks and deadlines for all attendees\n",
        "for attendee in attendees:\n",
        "    name = attendee[name_column]  # Dynamically use correct name column\n",
        "    tasks_and_deadlines = extract_tasks_and_deadlines(name, transcript_text)\n",
        "    attendee['Tasks & Deadlines'] = tasks_and_deadlines  # Add new column\n",
        "\n",
        "# Write updated data back to CSV\n",
        "output_csv_path = \"updated_attendance.csv\"  # Change to your desired output file\n",
        "with open(output_csv_path, 'w', newline='', encoding='utf-8') as csvfile:\n",
        "    writer = csv.DictWriter(csvfile, fieldnames=attendees[0].keys())\n",
        "    writer.writeheader()\n",
        "    writer.writerows(attendees)\n",
        "\n",
        "print(f\"✅ Tasks and deadlines added to '{output_csv_path}' for attendees with existing data.\")\n"
      ],
      "metadata": {
        "id": "IEbFBtQP-vB_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "48a9a458-e082-46c6-967e-b40d849623a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔹 Available columns in CSV: dict_keys(['\\ufeffFirst name', 'Last name', 'Email', 'Duration', 'Time joined', 'Time exited'])\n",
            "✅ Tasks and deadlines added to 'updated_attendance.csv' for attendees with existing data.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import smtplib\n",
        "import google.generativeai as genai\n",
        "from email.mime.text import MIMEText\n",
        "from email.mime.multipart import MIMEMultipart\n",
        "\n",
        "# ✅ Configure Gemini API Key\n",
        "genai.configure(api_key=\"AIzaSyBX9yIYHClYBl2PiEnshnh6OHm0dssXWwM\")\n",
        "\n",
        "# ✅ Function to load attendees from CSV (Fixes BOM issue)\n",
        "def load_attendees_from_csv(csv_file):\n",
        "    with open(csv_file, 'r', encoding='utf-8-sig') as file:\n",
        "        reader = csv.DictReader(file)\n",
        "        attendees = [row for row in reader]\n",
        "    return attendees\n",
        "\n",
        "# ✅ Function to send email\n",
        "def send_email(receiver_email, subject, message):\n",
        "    sender_email = \"himanshu.shekhar2022@vitstudent.ac.in\"  # Change to your email\n",
        "    sender_password = \"XXXXXXXXXXXXXX\"  # ⚠️ Hardcoded password (Replace this with actual password)\n",
        "\n",
        "    msg = MIMEMultipart()\n",
        "    msg['From'] = sender_email\n",
        "    msg['To'] = receiver_email\n",
        "    msg['Subject'] = subject.encode('utf-8').decode('utf-8')  # ✅ Fix encoding\n",
        "\n",
        "    msg.attach(MIMEText(message, 'plain', 'utf-8'))\n",
        "\n",
        "    try:\n",
        "        server = smtplib.SMTP('smtp.gmail.com', 587)\n",
        "        server.starttls()\n",
        "        server.login(sender_email, sender_password)\n",
        "        server.sendmail(sender_email, receiver_email, msg.as_string())\n",
        "        server.quit()\n",
        "        print(f\"✅ Email sent successfully to {receiver_email}\")\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Email sending failed to {receiver_email}: {e}\")\n",
        "\n",
        "# ✅ Function to extract tasks and deadlines using Gemini\n",
        "def extract_tasks_and_deadlines(attendee_name, transcript_text):\n",
        "    prompt = f\"\"\"\n",
        "    Extract and list only the tasks and deadlines assigned to {attendee_name} from the meeting transcript.\n",
        "    If no specific tasks are assigned, respond with 'No tasks assigned.'\n",
        "\n",
        "    **Meeting Transcript:**\n",
        "    {transcript_text}\n",
        "\n",
        "    **Tasks & Deadlines for {attendee_name}:**\n",
        "    \"\"\"\n",
        "\n",
        "    model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
        "    response = model.generate_content(prompt)\n",
        "    return response.text.strip() if response.text else \"No tasks assigned.\"\n",
        "\n",
        "# ✅ Load attendees from CSV\n",
        "csv_file_path = \"/content/drive/MyDrive/tarp1/attandence.csv\"  # Update with actual path\n",
        "attendees = load_attendees_from_csv(csv_file_path)\n",
        "\n",
        "# ✅ Load the transcript text file\n",
        "transcript_file_path = \"/content/drive/MyDrive/tarp1/meet_transcript.txt\"  # Update with actual path\n",
        "try:\n",
        "    with open(transcript_file_path, 'r', encoding='utf-8') as file:\n",
        "        transcript_text = file.read()\n",
        "except FileNotFoundError:\n",
        "    print(f\"❌ Error: Transcript file '{transcript_file_path}' not found!\")\n",
        "    exit()\n",
        "\n",
        "# ✅ Extract tasks and send emails\n",
        "for attendee in attendees:\n",
        "    name_column = list(attendees[0].keys())[0]  # Fixes BOM issue\n",
        "    name = attendee[name_column]\n",
        "    email = attendee['Email']\n",
        "\n",
        "    # Extract tasks using Gemini\n",
        "    tasks_and_deadlines = extract_tasks_and_deadlines(name, transcript_text)\n",
        "    attendee['Tasks & Deadlines'] = tasks_and_deadlines  # Update attendee data\n",
        "\n",
        "    # Email content\n",
        "    subject = f\"Task Assignment from Meeting - {name}\"\n",
        "    message = f\"Dear {name},\\n\\nHere are your assigned tasks:\\n\\n{tasks_and_deadlines}\\n\\nBest Regards,\\nHimanshu Shekhar\"\n",
        "\n",
        "    # Send email\n",
        "    send_email(email, subject, message)\n",
        "\n",
        "# ✅ Write updated data back to CSV\n",
        "output_csv_path = \"/content/updated_attendance.csv\"\n",
        "with open(output_csv_path, 'w', newline='', encoding='utf-8-sig') as csvfile:\n",
        "    writer = csv.DictWriter(csvfile, fieldnames=attendees[0].keys())\n",
        "    writer.writeheader()\n",
        "    writer.writerows(attendees)\n",
        "\n",
        "print(f\"\\n✅ Tasks and deadlines added to '{output_csv_path}' for attendees.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        },
        "id": "8DDoj6hTm9Gq",
        "outputId": "b16b9381-db4b-4952-8e73-f1edfca3d4ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Email sent successfully to himanshu.shekhar2022@vitstudent.ac.in\n",
            "✅ Email sent successfully to aarushi.kumari2022@vitstudent.ac.in\n",
            "✅ Email sent successfully to vibhuti.dua2022@vitstudent.ac.in\n",
            "❌ Email sending failed to vibh******@***.com: {'vibh******@***.com': (553, b'5.1.3 The recipient address <vibh******@***.com> is not a valid RFC 5321\\n5.1.3 address. For more information, go to\\n5.1.3  https://support.google.com/a/answer/3221692 and review RFC 5321\\n5.1.3 specifications. ca18e2360f4ac-861532c1dd7sm39543139f.9 - gsmtp')}\n",
            "\n",
            "✅ Tasks and deadlines added to '/content/updated_attendance.csv' for attendees.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
